{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11f1ebc",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2017/05/25-must-know-terms-concepts-for-beginners-in-deep-learning/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca336e",
   "metadata": {},
   "source": [
    "# Twython\n",
    "## Loading Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239e2648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',100) # güncellenmiş max_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdbdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install twython \n",
    "from twython import Twython\n",
    "CONSUMER_KEY = \"0pJRCT1emkOcrtxHl7lMN4N5A\"\n",
    "               \n",
    "CONSUMER_SECRET = \"IS4Gxcx1aQ1c5Hyei5PSePLS37IcVmYBT8Qt1t4IOxmLIxJD42\"\n",
    "\n",
    "twitter = Twython(CONSUMER_KEY,CONSUMER_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ba533",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06adc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(Twython)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Twython).search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f219a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = twitter.search(q=\"data science\", count = 200)\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a104aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = results[\"statuses\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57aba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(all_items)\n",
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fffbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_user = pd.DataFrame([d[\"user\"] for d in results[\"statuses\"]])\n",
    "tweet_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe0f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = tweet_df.merge(tweet_user, left_index=True, right_index=True) # birleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e151f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a7353e",
   "metadata": {},
   "source": [
    "## Finding locations of most Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa4cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.location.value_counts().plot(kind=\"bar\", figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b09f05",
   "metadata": {},
   "source": [
    "## Pulling 200 tweets with search term 'data science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd126d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_screenname = []\n",
    "user_location = []\n",
    "user_name = []\n",
    "user_tz = []\n",
    "tweet_text = []\n",
    "tweet_tm = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddc986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for status in twitter.search(q = \"Datascience\", result_type = \"popular\",\n",
    "                             lang = \"en\",count = 200)[\"statuses\"]:\n",
    "    user = status[\"user\"][\"screen_name\"]\n",
    "    text = status[\"text\"]\n",
    "    tm = status[\"created_at\"]        \n",
    "    loc = status[\"user\"][\"location\"]\n",
    "    nm = status[\"user\"][\"name\"]\n",
    "    tz = status[\"user\"][\"time_zone\"]\n",
    "    \n",
    "    print()\n",
    "    print(user,\"--\",loc,\"--\",nm,\"--\",tm,\"--\",text)\n",
    "    print()\n",
    "\n",
    "    user_screenname.append(user)\n",
    "    user_location.append(loc)\n",
    "    user_name.append(nm)\n",
    "    user_tz.append(tz)\n",
    "    tweet_text.append(text)\n",
    "    tweet_tm.append(tm)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ad57da",
   "metadata": {},
   "source": [
    "## Placing Tweets into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f709f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = twitter_df[[\"created_at_x\",\"text\"]]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3965e110",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(\"created_at_x\",axis=1, inplace=True)\n",
    "test.rename(columns={\"text\":\"SentimentText\"},inplace=True) # column name değiştirme\n",
    "test.index.names=[\"ItemID\"] # \n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314fa5e4",
   "metadata": {},
   "source": [
    "## Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a6713",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9f8c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c28e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be8211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def detect_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cba66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"Sentiment\"]=test.SentimentText.apply(detect_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba0f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d3a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c14522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates\n",
    "df.SentimentText.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b753d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=\"SentimentText\", inplace=True) # tekrar edenleri sil\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d074711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing special characters\n",
    "df[\"removal_char\"]=df[\"SentimentText\"].str.replace(\"[^a-zA-Z0-9\\s]\",'') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing and tokenizing words\n",
    "df.removal_char = df.removal_char.apply(lambda x: word_tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a34586",
   "metadata": {},
   "outputs": [],
   "source": [
    "TextBlob(\"I am very happy\").sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fcb55f",
   "metadata": {},
   "source": [
    "## Checking for distribution of negative and positive sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553d470",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4ddba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x=df[\"Sentiment\"])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0fedfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob, Word\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc4ef7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words=list(stopwords.words(\"english\"))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6242c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Stopwords\n",
    "df[\"stopword_removal\"] = df[\"removal_char\"].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stopword_removal\"] = df[\"stopword_removal\"].apply(lambda x: \" \".join(x)) # kelimleri birleştirdik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6e55cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer # kök bulma\n",
    "df[\"stopword_removal\"]=df[\"stopword_removal\"].apply(lambda x : WordNetLemmatizer().lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf0c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Polarity\n",
    "df[\"sentiment_polarity\"]=df[\"stopword_removal\"].apply(lambda x : TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Subjectivity\n",
    "df[\"sentiment_subjectivity\"]=df[\"stopword_removal\"].apply(lambda x : TextBlob(x).sentiment.subjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=CountVectorizer()\n",
    "X=vect.fit_transform(df[\"stopword_removal\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91843371",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57f23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9381615",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b79e237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad98b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "log = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentence(score): \n",
    "    if score>0.2: \n",
    "        return 2 \n",
    "    elif score<-0.2: \n",
    "        return 0 \n",
    "    else: \n",
    "        return 1 \n",
    "df[\"class\"]=df[\"sentiment_polarity\"].apply(lambda x: tweet_sentence(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcc9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[\"stopword_removal\"]\n",
    "y=df[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1ca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dtm=vect.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5abcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a37289",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = [nb, log, dtc]\n",
    "names = ['MultinomialNB', 'LogisticRegression', 'DecisionTreeClassifier'] \n",
    "def classification(): \n",
    "    accuracy = [] \n",
    "    precision = [] \n",
    "    recall = [] \n",
    "    f1 =[] \n",
    "    for i in range(len(algorithms)):\n",
    "        algorithms[i].fit(x_dtm, y) \n",
    "    for i in range(len(algorithms)): \n",
    "        accuracy.append(accuracy_score(y, algorithms[i].predict(x_dtm))) \n",
    "        precision.append(precision_score(y, algorithms[i].predict(x_dtm),average=\"weighted\")) \n",
    "        recall.append(recall_score(y, algorithms[i].predict(x_dtm),average=\"weighted\")) \n",
    "        f1.append(f1_score(y, algorithms[i].predict(x_dtm),average=\"weighted\")) \n",
    "   \n",
    "    met = pd.DataFrame(columns = ['Accuracy', 'Precision', 'Recall', 'F1'], index = names) \n",
    "    met['Accuracy'] = accuracy \n",
    "    met['Precision'] = precision \n",
    "    met['Recall'] = recall \n",
    "    met[\"F1\"] = f1 \n",
    "    return met "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bffecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification() # train test split yapmadığımzdan, sonuçları ezberledi gibi yani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9617fe9",
   "metadata": {},
   "source": [
    "# RNN (Recurrent Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8327e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41e231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv(\"Google_Stock_Price_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbb21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96209731",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a40eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set # array oluypr artık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445d4205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler() # default is 0,1\n",
    "training_set = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320bd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set[0:1257]\n",
    "y_train = training_set[1:1258]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54192a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdafe82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (1257,1,1)) # data frame olmadığından böyle yaptık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63af3f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ab852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=4, activation=\"sigmoid\", input_shape=(None,1)))\n",
    "regressor.add(Dense(units=1))\n",
    "regressor.compile(optimizer=\"adam\",loss=\"mean_squared_error\")\n",
    "regressor.fit(X_train, y_train, batch_size=32, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ce5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"Google_Stock_Price_Test.csv\")\n",
    "real_stock_price = test_set.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c63c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = real_stock_price\n",
    "inputs = sc.transform(inputs)\n",
    "inputs = np.reshape(inputs, (20,1,1))\n",
    "predicted_stock_price = regressor.predict(inputs)\n",
    "predicted_stock_price = sc.inverse_transform(predicted_stock_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54415a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_stock_price, color=\"red\", label=\"Real Google Stock Price\")\n",
    "plt.plot(predicted_stock_price, color=\"blue\", label=\"Predicted Google Stock Price\")\n",
    "plt.title(\"Google Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Google Time Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91072c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_stock_price = pd.read_csv(\"Google_Stock_Price_Train.csv\")\n",
    "real_stock_price = real_stock_price.iloc[:,1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130ce42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price_train = regressor.predict(X_train)\n",
    "predicted_stock_price_train = sc.inverse_transform(predicted_stock_price_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13897b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_stock_price, color=\"red\", label=\"Real Google Stock Price\")\n",
    "plt.plot(predicted_stock_price_train, color=\"blue\", label=\"Predicted Google Stock Price\")\n",
    "plt.title(\"Google Stock Price Prediction\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Google Time Price\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfc7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6476003",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb9ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = new_model.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e602f41a",
   "metadata": {},
   "source": [
    "# Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "import numpy as np \n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2839bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"AirPassengers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54076778",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557580b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f807b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.plot(df[\"#Passengers\"])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab78243",
   "metadata": {},
   "source": [
    "#### Checking how Stationary the data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4072f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller \n",
    "\n",
    "def test_stationarity(timeseries): \n",
    "  rolmean = timeseries.rolling(window=12).mean() \n",
    "  rolstd = timeseries. rolling(window=12).std()\n",
    "\n",
    "  plt.figure(figsize=(8,5)) \n",
    "  orig = plt.plot(timeseries, color='blue',label='Original') \n",
    "  mean = plt.plot(rolmean, color='red', label='Rolling Mean') \n",
    "  std = plt.plot(rolstd, color='black', label = 'Rolling Std') \n",
    "  plt.legend(loc='best') \n",
    "  plt.title('Rolling Mean & Standard Deviation') \n",
    "  plt.show(block=False) \n",
    "  \n",
    "  #Perform Dickey-Fuller test: \n",
    "  print ('Results of Dickey-Fuller Test:') \n",
    "  #iki çizgi arasında olup olmadığına bakmak için bu testi yapıyoruz\n",
    "  dftest = adfuller(timeseries, autolag='AIC') \n",
    "  dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used']) \n",
    "  for key,value in dftest[4].items(): \n",
    "    dfoutput['Critical Value (%s)'%key] = value \n",
    "  print (dfoutput) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd25bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stationarity(df[\"#Passengers\"]) # gün geçtikçe ortalama değişiyor (rolling mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fd5193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
